{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeT_3 test decoder notebook\n",
    "\n",
    "Author: Jason Jiang (Xunfun Lee)\n",
    "\n",
    "Data: 2024.1.16\n",
    "\n",
    "Since i am not sure if the architecture of the decoder is correct, i write this notebook to test the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: cuda\n",
      "CUDA device numbers:  1\n"
     ]
    }
   ],
   "source": [
    "from PythonScripts.transformer import DecoderV1\n",
    "from PythonScripts.utility import SetDevice\n",
    "\n",
    "device = SetDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_instance = DecoderV1(device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "output_encoder = torch.rand((1, 12, 768)).to(device)\n",
    "input_decoder = torch.rand((1, 3000, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder x.shape: torch.Size([1, 3000, 1])\n"
     ]
    }
   ],
   "source": [
    "output_decoder = decoder_instance(output_encoder=output_encoder, decoder_input=input_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_decoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_decoder = decoder_instance(output_encoder=output_decoder, decoder_input=None)\n",
    "output_decoder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one seq\n",
    "output_encoder_seq_one = torch.rand((1, 12, 768)).to(device)\n",
    "input_decoder_seq_one = torch.rand((1, 1, 768)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PythonScripts.transformer import DecoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecoderBlock_instance = DecoderBlock().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_decoder_block, mha, cmha = DecoderBlock_instance(input_decoder_seq_one, input_decoder_seq_one, input_decoder_seq_one, output_encoder_seq_one)\n",
    "\n",
    "output_decoder_block.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test small patch embedding block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PythonScripts.transformer import SmallPatchEmbeddingBlock\n",
    "\n",
    "SPE_instance = SmallPatchEmbeddingBlock().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.rand((1, 1, 250)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_SPE = SPE_instance(input_tensor)\n",
    "\n",
    "output_SPE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, torch.Size([1, 1, 250]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你的输入tensor是input_tensor，其形状为(batch_size, 3000, 1)\n",
    "input_tensor = torch.rand((1, 3000, 1)).to(device)\n",
    "\n",
    "# 将tensor沿第二个维度（长度为3000的维度）分割成12份\n",
    "chunks = torch.chunk(input_tensor, 12, dim=1)\n",
    "\n",
    "# 每个chunk的形状现在是(batch_size, 250, 1)\n",
    "# 如果需要将最后一个维度从1变成250，可以使用torch.squeeze和torch.unsqueeze\n",
    "reshaped_chunks = [torch.unsqueeze(torch.squeeze(chunk, -1), 1) for chunk in chunks]\n",
    "\n",
    "# 现在reshaped_chunks是一个包含12个形状为(batch_size, 1, 250)的tensor列表\n",
    "len(reshaped_chunks), reshaped_chunks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
